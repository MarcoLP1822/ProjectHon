{"bookId":"675af1d267c607f402f3ac0b","error":"TypeError: extractAndSaveText is not a function\n    at validateBookContent (/Users/marcolp/AI/CURSOR projects/Lose/backend/utils/bookUtils.js:32:29)\n    at exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:137:31)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)","level":"error","message":"Error generating categories: extractAndSaveText is not a function","timestamp":"2024-12-12T15:28:09.874Z"}
{"bookId":"675b0830f7a47311c7efb1bc","error":"Error: 400 This request has been blocked by our content filters.\n    at APIError.generate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/error.js:45:20)\n    at OpenAI.makeStatusError (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:293:33)\n    at OpenAI.makeRequest (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:337:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async generateCoverImage (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:366:22)\n    at async /Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:235:25\n    at async Promise.all (index 2)\n    at async exports.generateCoverImages (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:247:20)","level":"error","message":"Error generating cover images: 400 This request has been blocked by our content filters.","timestamp":"2024-12-12T16:05:00.284Z"}
{"bookId":"675b0830f7a47311c7efb1bc","error":"Error: Invalid keywords format received from OpenAI\n    at validateResponse (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:129:13)\n    at /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:246:12\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:96:14)\n    at async exports.generateKeywords (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:131:22)","level":"error","message":"Error generating keywords: Invalid keywords format received from OpenAI","timestamp":"2024-12-13T13:20:26.074Z"}
{"bookId":"675b0830f7a47311c7efb1bc","error":"Error: Invalid keywords format received from OpenAI\n    at validateResponse (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:129:13)\n    at /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:246:12\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:96:14)\n    at async exports.generateKeywords (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:131:22)","level":"error","message":"Error generating keywords: Invalid keywords format received from OpenAI","timestamp":"2024-12-13T13:21:42.038Z"}
{"bookId":"675b0830f7a47311c7efb1bc","error":"Error: Invalid keywords format received from OpenAI\n    at validateResponse (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:129:13)\n    at /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:246:12\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:96:14)\n    at async exports.generateKeywords (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:131:22)","level":"error","message":"Error generating keywords: Invalid keywords format received from OpenAI","timestamp":"2024-12-13T13:22:01.969Z"}
{"bookId":"675cc0f0c77c43d34af8b0d6","error":"ReferenceError: extractText is not defined\n    at extractAndSaveText (/Users/marcolp/AI/CURSOR projects/Lose/backend/utils/bookUtils.js:28:31)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async validateBookContent (/Users/marcolp/AI/CURSOR projects/Lose/backend/utils/bookUtils.js:102:21)\n    at async exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:82:25)","level":"error","message":"Error generating categories: extractText is not defined","timestamp":"2024-12-13T23:29:59.967Z"}
{"bookId":"675cc0f0c77c43d34af8b0d6","error":"ReferenceError: prepareChunksForProcessing is not defined\n    at /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:181:28\n    at withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:97:20)\n    at async exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:90:24)","level":"error","message":"Error generating categories: prepareChunksForProcessing is not defined","timestamp":"2024-12-13T23:31:08.966Z"}
{"bookId":"675cc0f0c77c43d34af8b0d6","error":"TypeError: chunks[0]?.text?.substring is not a function\n    at prepareChunksForProcessing (/Users/marcolp/AI/CURSOR projects/Lose/backend/utils/chunkingUtils.js:221:35)\n    at /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:181:28\n    at withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:97:20)\n    at async exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:90:24)","level":"error","message":"Error generating categories: chunks[0]?.text?.substring is not a function","timestamp":"2024-12-13T23:32:10.355Z"}
{"bookId":"675cc0f0c77c43d34af8b0d6","error":"TypeError: chunks[0]?.text?.substring is not a function\n    at prepareChunksForProcessing (/Users/marcolp/AI/CURSOR projects/Lose/backend/utils/chunkingUtils.js:227:26)\n    at /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:181:28\n    at withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:97:20)\n    at async exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:90:24)","level":"error","message":"Error generating categories: chunks[0]?.text?.substring is not a function","timestamp":"2024-12-13T23:32:57.427Z"}
{"bookId":"675cc55409a5f4752be20abe","error":"Error: Failed to extract text from file: Cannot find module '/Users/marcolp/node_modules/pdfjs-dist/build/pdf.js' imported from /Users/marcolp/AI/CURSOR projects/Lose/backend/utils/bookUtils.js\n    at extractText (/Users/marcolp/AI/CURSOR projects/Lose/backend/utils/bookUtils.js:261:15)\n    at async extractAndSaveText (/Users/marcolp/AI/CURSOR projects/Lose/backend/utils/bookUtils.js:87:31)\n    at async validateBookContent (/Users/marcolp/AI/CURSOR projects/Lose/backend/utils/bookUtils.js:169:21)\n    at async exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:82:25)","level":"error","message":"Error generating categories: Failed to extract text from file: Cannot find module '/Users/marcolp/node_modules/pdfjs-dist/build/pdf.js' imported from /Users/marcolp/AI/CURSOR projects/Lose/backend/utils/bookUtils.js","timestamp":"2024-12-13T23:59:18.049Z"}
{"bookId":"675e274a41c696ef31c3b9a4","error":"Error: 400 This model's maximum context length is 8192 tokens, however you requested 50086 tokens (50086 in your prompt; 0 for the completion). Please reduce your prompt; or completion length.\n    at APIError.generate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/error.js:45:20)\n    at OpenAI.makeStatusError (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:293:33)\n    at OpenAI.makeRequest (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:337:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:138:31\n    at async withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:48:14)\n    at async exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:90:24)","level":"error","message":"Error generating categories: 400 This model's maximum context length is 8192 tokens, however you requested 50086 tokens (50086 in your prompt; 0 for the completion). Please reduce your prompt; or completion length.","timestamp":"2024-12-16T16:45:40.341Z"}
{"bookId":"675e274a41c696ef31c3b9a4","error":"ReferenceError: queryText is not defined\n    at BisacService.searchBisacCodesWithEmbedding (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/bisac.service.js:33:42)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:147:31\n    at async withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:48:14)\n    at async exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:90:24)","level":"error","message":"Error generating categories: queryText is not defined","timestamp":"2024-12-16T16:50:40.379Z"}
{"bookId":"675e274a41c696ef31c3b9a4","error":"ValidationError: Generated categories is invalid or incomplete\n    at exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:92:13)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)","level":"error","message":"Error generating categories: Generated categories is invalid or incomplete","timestamp":"2024-12-16T17:36:38.361Z"}
{"bookId":"675e274a41c696ef31c3b9a4","error":"ValidationError: Generated categories is invalid or incomplete\n    at exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:92:13)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)","level":"error","message":"Error generating categories: Generated categories is invalid or incomplete","timestamp":"2024-12-16T17:39:59.737Z"}
{"bookId":"675e274a41c696ef31c3b9a4","error":"ValidationError: Generated categories is invalid or incomplete\n    at exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:92:13)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)","level":"error","message":"Error generating categories: Generated categories is invalid or incomplete","timestamp":"2024-12-16T21:49:59.805Z"}
{"bookId":"675e274a41c696ef31c3b9a4","error":"ValidationError: Generated categories is invalid or incomplete\n    at exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:92:13)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)","level":"error","message":"Error generating categories: Generated categories is invalid or incomplete","timestamp":"2024-12-16T21:52:47.339Z"}
{"bookId":"675e274a41c696ef31c3b9a4","error":"ValidationError: Generated categories is invalid or incomplete\n    at exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:92:13)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)","level":"error","message":"Error generating categories: Generated categories is invalid or incomplete","timestamp":"2024-12-16T21:55:13.808Z"}
{"bookId":"67644de548cb00bc1fc2fe8c","error":"CastError: Cast to [string] failed for value \"[\\n' +\n  '  {\\n' +\n  '    keywords: [\\n' +\n  \"      'Accessibilità',\\n\" +\n  \"      'Intelligenza Artificiale',\\n\" +\n  \"      'Disabilità Visiva',\\n\" +\n  \"      'Tecnologie Assistive',\\n\" +\n  \"      'Autonomia',\\n\" +\n  \"      'Assistenza Visiva',\\n\" +\n  \"      'Privacy'\\n\" +\n  '    ]\\n' +\n  '  }\\n' +\n  ']\" (type string) at path \"metadata.keywords.0\" because of \"CastError\"\n    at SchemaArray.cast (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/schema/array.js:401:15)\n    at SchemaArray.cast (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/schema/array.js:415:17)\n    at SchemaType.applySetters (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/schematype.js:1219:12)\n    at castUpdateVal (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/helpers/query/castUpdate.js:574:21)\n    at walkUpdatePath (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/helpers/query/castUpdate.js:280:26)\n    at castUpdate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/helpers/query/castUpdate.js:110:7)\n    at model.Query._castUpdate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/query.js:4727:10)\n    at model.Query._findOneAndUpdate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/query.js:3341:23)\n    at model.Query.exec (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/query.js:4447:28)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async exports.generateKeywords (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:143:25)","level":"error","message":"Error generating keywords: Cast to [string] failed for value \"[\\n' +\n  '  {\\n' +\n  '    keywords: [\\n' +\n  \"      'Accessibilità',\\n\" +\n  \"      'Intelligenza Artificiale',\\n\" +\n  \"      'Disabilità Visiva',\\n\" +\n  \"      'Tecnologie Assistive',\\n\" +\n  \"      'Autonomia',\\n\" +\n  \"      'Assistenza Visiva',\\n\" +\n  \"      'Privacy'\\n\" +\n  '    ]\\n' +\n  '  }\\n' +\n  ']\" (type string) at path \"metadata.keywords.0\" because of \"CastError\"","timestamp":"2024-12-20T08:15:08.330Z"}
{"bookId":"67644de548cb00bc1fc2fe8c","error":"CastError: Cast to [string] failed for value \"[\\n' +\n  '  {\\n' +\n  '    keywords: [\\n' +\n  \"      'Accessibilità',\\n\" +\n  \"      'Intelligenza Artificiale',\\n\" +\n  \"      'Tecnologie Assistive',\\n\" +\n  \"      'VoiceOver',\\n\" +\n  \"      'Tecnologia Assistiva',\\n\" +\n  \"      'Autonomia Digitale',\\n\" +\n  \"      'Disabilità Visiva'\\n\" +\n  '    ]\\n' +\n  '  }\\n' +\n  ']\" (type string) at path \"metadata.keywords.0\" because of \"CastError\"\n    at SchemaArray.cast (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/schema/array.js:401:15)\n    at SchemaArray.cast (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/schema/array.js:415:17)\n    at SchemaType.applySetters (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/schematype.js:1219:12)\n    at castUpdateVal (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/helpers/query/castUpdate.js:574:21)\n    at walkUpdatePath (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/helpers/query/castUpdate.js:280:26)\n    at castUpdate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/helpers/query/castUpdate.js:110:7)\n    at model.Query._castUpdate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/query.js:4727:10)\n    at model.Query._findOneAndUpdate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/query.js:3341:23)\n    at model.Query.exec (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/query.js:4447:28)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async exports.generateKeywords (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:143:25)","level":"error","message":"Error generating keywords: Cast to [string] failed for value \"[\\n' +\n  '  {\\n' +\n  '    keywords: [\\n' +\n  \"      'Accessibilità',\\n\" +\n  \"      'Intelligenza Artificiale',\\n\" +\n  \"      'Tecnologie Assistive',\\n\" +\n  \"      'VoiceOver',\\n\" +\n  \"      'Tecnologia Assistiva',\\n\" +\n  \"      'Autonomia Digitale',\\n\" +\n  \"      'Disabilità Visiva'\\n\" +\n  '    ]\\n' +\n  '  }\\n' +\n  ']\" (type string) at path \"metadata.keywords.0\" because of \"CastError\"","timestamp":"2024-12-20T08:16:38.296Z"}
{"bookId":"676546bbff60993ad199efe0","error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 157518 tokens. Please reduce the length of the messages.\n    at APIError.generate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/error.js:45:20)\n    at OpenAI.makeStatusError (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:293:33)\n    at OpenAI.makeRequest (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:337:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:258:26\n    at async withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:67:14)\n    at async exports.generateKeywords (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:138:22)","level":"error","message":"Error generating keywords: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 157518 tokens. Please reduce the length of the messages.","timestamp":"2024-12-20T10:28:28.706Z"}
{"bookId":"676546bbff60993ad199efe0","error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 150970 tokens. Please reduce the length of the messages.\n    at APIError.generate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/error.js:45:20)\n    at OpenAI.makeStatusError (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:293:33)\n    at OpenAI.makeRequest (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:337:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:582:24\n    at async withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:67:14)\n    at async exports.generateSynopsis (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:423:22)","level":"error","message":"Error generating synopsis: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 150970 tokens. Please reduce the length of the messages.","timestamp":"2024-12-20T10:28:29.744Z"}
{"bookId":"676546bbff60993ad199efe0","error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 151003 tokens. Please reduce the length of the messages.\n    at APIError.generate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/error.js:45:20)\n    at OpenAI.makeStatusError (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:293:33)\n    at OpenAI.makeRequest (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:337:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:419:24\n    at async withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:67:14)\n    at async exports.generateBackCover (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:303:23)","level":"error","message":"Error generating back cover: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 151003 tokens. Please reduce the length of the messages.","timestamp":"2024-12-20T10:28:31.289Z"}
{"bookId":"676546bbff60993ad199efe0","error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 151061 tokens. Please reduce the length of the messages.\n    at APIError.generate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/error.js:45:20)\n    at OpenAI.makeStatusError (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:293:33)\n    at OpenAI.makeRequest (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:337:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:470:24\n    at async withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:67:14)\n    at async exports.generatePreface (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:343:21)","level":"error","message":"Error generating preface: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 151061 tokens. Please reduce the length of the messages.","timestamp":"2024-12-20T10:28:33.007Z"}
{"bookId":"676546bbff60993ad199efe0","error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 157515 tokens. Please reduce the length of the messages.\n    at APIError.generate (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/error.js:45:20)\n    at OpenAI.makeStatusError (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:293:33)\n    at OpenAI.makeRequest (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/openai/core.js:337:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:168:26\n    at async withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:67:14)\n    at async exports.generateCategories (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:90:24)","level":"error","message":"Error generating categories: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 157515 tokens. Please reduce the length of the messages.","timestamp":"2024-12-20T10:28:33.973Z"}
{"bookId":"67656b5ecadad13c67eace22","error":"Error: Failed to extract text: File at path [[ uploads\\1734699867599-102842357.docx ]] does not exist.\n    at extractAndSaveText (/Users/marcolp/AI/CURSOR projects/Lose/backend/utils/bookUtils.js:63:19)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async validateBookContent (/Users/marcolp/AI/CURSOR projects/Lose/backend/utils/bookUtils.js:142:21)\n    at async exports.generateKeywords (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:131:25)","level":"error","message":"Error generating keywords: Failed to extract text: File at path [[ uploads\\1734699867599-102842357.docx ]] does not exist.","timestamp":"2024-12-20T13:06:36.987Z"}
{"bookId":"6771a2ef5971e1dc5bae13e3","error":"Error: Rolling summary not found\n    at /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:251:13\n    at withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:67:20)\n    at async exports.generateKeywords (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:81:22)","level":"error","message":"Error generating keywords: Rolling summary not found","timestamp":"2024-12-29T19:30:03.350Z"}
{"bookId":"6771a3cec664dc76f2a5c184","error":"Error: Rolling summary not found\n    at /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:594:13\n    at withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:67:20)\n    at async exports.generateSynopsis (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:346:22)","level":"error","message":"Error generating synopsis: Rolling summary not found","timestamp":"2024-12-29T19:36:00.577Z"}
{"bookId":"6771a3cec664dc76f2a5c184","error":"Error: Rolling summary not found\n    at /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:423:13\n    at withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:67:20)\n    at async exports.generateBackCover (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:226:23)","level":"error","message":"Error generating back cover: Rolling summary not found","timestamp":"2024-12-29T19:36:43.580Z"}
{"bookId":"6771a3cec664dc76f2a5c184","error":"Error: Rolling summary not found\n    at /Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:479:13\n    at withRetry (/Users/marcolp/AI/CURSOR projects/Lose/backend/services/openai.js:67:20)\n    at async exports.generatePreface (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:266:21)","level":"error","message":"Error generating preface: Rolling summary not found","timestamp":"2024-12-29T19:36:47.253Z"}
{"bookId":"6794ba6acb044fc74d23b1ee","error":"VersionError: No matching document found for id \"6794ba6acb044fc74d23b1ee\" version 0 modifiedPaths \"metadata, metadata.keywords\"\n    at generateVersionError (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/model.js:465:10)\n    at model.save (/Users/marcolp/AI/CURSOR projects/Lose/backend/node_modules/mongoose/lib/model.js:522:28)\n    at exports.generateKeywords (/Users/marcolp/AI/CURSOR projects/Lose/backend/controllers/ai.controller.js:76:16)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)","level":"error","message":"Error generating keywords:","timestamp":"2025-01-25T10:18:44.186Z"}
